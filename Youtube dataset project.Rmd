---
title: "R Notebook"
output:
  html_document:
    df_print: paged
---
``````{r}
plot(cars)
```{r}
```

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Ctrl+Shift+Enter*. 



Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Ctrl+Alt+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Ctrl+Shift+K* to preview the HTML file).

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.

```{r}
#1. Import Dataset
```

```{r}
dataset<- read.csv("C:/Users/sonia/Downloads/CAvideos.csv/CAvideos.csv", stringsAsFactors = FALSE)
```

```{r}
#2. Install Packages and libraries
```

```{r}
install.packages("tidyverse")
install.packages("tm")
install.packages("SnowballC")
install.packages("ggcorrplot")
install.packages("wordcloud")
install.packages("RColorBrewer")
install.packages("wordcloud2")
install.packages("word2vec")
install.packages("lsa")
```


```{r}
options(warn=-1)
library(tidyverse)
library(stringr)
library(tm)
library(SnowballC)
library(dplyr)
library(ggcorrplot)
library("wordcloud")
library("RColorBrewer")
library(wordcloud2)
library(lubridate)
library(class)
library(word2vec)
library(lsa)
```

```{r}
#3. Examine dataset
```

```{r}
#Dimensions
dim(dataset)
```

```{r}
#Summary
summary(dataset)
```

```{r}
#4. Clean data
```

```{r}
#Check null values
lapply(dataset,function(x) { length(which(is.na(x)))})
```


```{r}
#convert trending_date and publish_time from character to date
dataset$publish_time <- ymd_hms(dataset$publish_time)
dataset$trending_date<- ydm(dataset$trending_date)
#Check class
str(dataset$publish_time)
str(dataset$trending_date)
```

```{r}
#Clean title column

# Lowercase
dataset$title <- tolower(dataset$title)

# Remove everything that is not a number or letter
dataset$title <- stringr::str_replace_all(dataset$title,"[^a-zA-Z\\s]", " ")

# Remove double white spaces
dataset$title <- stringr::str_replace_all(dataset$title,"[\\s]+", " ")

#Remove stop words
dataset$title <- removeWords(dataset$title,stopwords())

#Remove emoticons
dataset$title = gsub("[^\x01-\x7F]", "", dataset$title)

#Check results of the first 10 rows
dataset$title[1:10]
```
```{r}
#Clean channel_title

# Lowercase
dataset$channel_title <- tolower(dataset$channel_title)

# Remove everything that is not a number or letter
dataset$channel_title <- stringr::str_replace_all(dataset$channel_title,"[^a-zA-Z\\s]", " ")

# Remove double white spaces
dataset$channel_title <- stringr::str_replace_all(dataset$channel_title,"[\\s]+", " ")

#Remove 1 and 2 letter words
dataset$channel_title <- gsub(" *\\b[[:alpha:]]{1,2}\\b *", " ", dataset$channel_title)

#Remove stop words
dataset$channel_title <- removeWords(dataset$channel_title,stopwords())

#Remove emoticons
dataset$channel_title = gsub("[^\x01-\x7F]", "", dataset$channel_title)

#Check results of first 10 rows
dataset$channel_title[1:10]
```

```{r}
#Clean description column

# Lowercase
dataset$description <- tolower(dataset$description)

#Remove Urls
dataset$description <- gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", dataset$description )

# Remove everything that is not a number or letter
dataset$description <- stringr::str_replace_all(dataset$description,"[^a-zA-Z\\s]", " ")

# Remove double white spaces
dataset$description <- stringr::str_replace_all(dataset$description,"[\\s]+", " ")

#Remove 1 and 2 letter words
dataset$description <- gsub(" *\\b[[:alpha:]]{1,2}\\b *", " ", dataset$description)

#Remove stop words
dataset$description <- removeWords(dataset$description,stopwords())

#Check results of first 5 rows
dataset$description[1:5]
```
```{r}
#Clean tags

# Lowercase
dataset$tags <- tolower(dataset$tags)

# Remove everything that is not a number or letter
dataset$tags <- stringr::str_replace_all(dataset$tags,"[^a-zA-Z\\s]", " ")

# Remove double white spaces
dataset$tags <- stringr::str_replace_all(dataset$tags,"[\\s]+", " ")

#Remove 1 and 2 letter words
dataset$tags <- gsub(" *\\b[[:alpha:]]{1,2}\\b *", " ", dataset$tags)

#Remove stop words
dataset$tags <- removeWords(dataset$tags,stopwords())

#Check results of first 10 rows
dataset$tags[1:10]
```
```{r}
#Categories are numerical, there is a Json document that explains what each category means in this link: https://www.kaggle.com/datasnaek/youtube-new?select=CA_category_id.json
#Likes, dislikes, comments_count and views are all numerical, so no need to convert
```

```{r}
#total number of unique videos
uniquevideos<- table(dataset$video_id)
length(uniquevideos)
```

```{r}
#remove duplicate videos, keep only one video, keep the video by highest view (by video_id)

#sort by number of views
sort_by_views<- dataset[order(dataset$video_id, dataset$views, decreasing=TRUE),] 

# take the first row within each id
unique_videos = sort_by_views[!duplicated(sort_by_views$video_id), ]
head(unique_videos[!duplicated(unique_videos$video_id), ])
dim(unique_videos)
```
```{r}
#5. Exploratory/Visual Analysis
#It is not possible in some instances to plot with a huge data, so we will only use the first 10k
df0<-unique_videos[order(-unique_videos$views),] #order by most views
head(df0)

#Select the first 10k
df1<-df0[1:10000,]
```


```{r}
#create a corpus
wc <- Corpus(VectorSource(df1$title))
tdm <- TermDocumentMatrix(wc)
m <- as.matrix(tdm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
```

```{r}
#Create a document-term-matrix

title_dtm <-TermDocumentMatrix(title_docs)
#title_matrix <- as.matrix(title_dtm)
#title_words <- sort(rowSums(title_matrix), decreasing=TRUE)
#title_df <- data.frame(word=names(title_words), freq=title_words)

#everytime I run as.matrix() it gives me the error below. How to fix it?
```
```{r}
#wordcloud of most common words found in trending titles
#Would the wordcloud below work?
set.seed(1234) # for reproducibility 
wordcloud(title_words = unique_videos$title, freq = unique_videos$freq, min.freq = 1,           max.words=200, random.order=FALSE, rot.per=0.35,colors=brewer.pal(8, "Dark2"))
```


```{r}
#match category_ids to category names using the Json filed provided with the dataset: https://www.kaggle.com/datasnaek/youtube-new?select=CA_category_id.json

unique_videos$category_id[unique_videos$category_id =="1"]<- "Film & Animation"
unique_videos$category_id[unique_videos$category_id =="2"]<- "Autos & Vehicles"
unique_videos$category_id[unique_videos$category_id =="10"]<- "Music"
unique_videos$category_id[unique_videos$category_id =="15"]<- "Pets & Animals"
unique_videos$category_id[unique_videos$category_id =="17"]<- "Sports"
unique_videos$category_id[unique_videos$category_id =="18"]<- "Short Movies"
unique_videos$category_id[unique_videos$category_id =="19"]<- "Travel & Events"
unique_videos$category_id[unique_videos$category_id =="20"]<- "Gaming"
unique_videos$category_id[unique_videos$category_id =="21"]<- "Videoblogging"
unique_videos$category_id[unique_videos$category_id =="22"]<- "People & Blogs"
unique_videos$category_id[unique_videos$category_id =="23"]<- "Comedy"
unique_videos$category_id[unique_videos$category_id =="24"]<- "Entertainment"
unique_videos$category_id[unique_videos$category_id =="25"]<- "News & Politics"
unique_videos$category_id[unique_videos$category_id =="26"]<- "Howto & Style"
unique_videos$category_id[unique_videos$category_id =="27"]<- "Education"
unique_videos$category_id[unique_videos$category_id =="28"]<- "Science & Technology"
unique_videos$category_id[unique_videos$category_id =="29"]<- "Education"
unique_videos$category_id[unique_videos$category_id =="30"]<- "Movies"
unique_videos$category_id[unique_videos$category_id =="31"]<- "Anime/Animation"
unique_videos$category_id[unique_videos$category_id =="32"]<- "Action/Adventure"
unique_videos$category_id[unique_videos$category_id =="34"]<- "Comedy"
unique_videos$category_id[unique_videos$category_id =="35"]<- "Documentary"
unique_videos$category_id[unique_videos$category_id =="36"]<- "Drama"
unique_videos$category_id[unique_videos$category_id =="37"]<- "Family"
unique_videos$category_id[unique_videos$category_id =="38"]<- "Foreign"
unique_videos$category_id[unique_videos$category_id =="39"]<- "Horror"
unique_videos$category_id[unique_videos$category_id =="40"]<- "Sci-Fi/Fantasy"
unique_videos$category_id[unique_videos$category_id =="41"]<- "Thriller"
unique_videos$category_id[unique_videos$category_id =="42"]<- "Shorts"
unique_videos$category_id[unique_videos$category_id =="43"]<- "Shows"
unique_videos$category_id[unique_videos$category_id =="44"]<- "Trailers"


#create table of the number of category_ids
unique(unique_videos[c("category_id")])
category_table <-table(unique_videos$category_id)

#df <- data[order(data$num,decreasing = TRUE),]
#category_df<-as.data.frame(category_table)
#category_df

#category_table_sort <- category_df[order(category_df$Frequency),]
#category_table_sort
```


```{r}
barplot(category_table, ylab="frequency", col = colors, horiz=F, las=2, cex.names = 0.7)
#add xlab but not have it hidden by the labels on the x-axis
#needs to be re-arranged in descending order
```



```{r}
# Load the data as a corpus
tags_docs <- Corpus(VectorSource(unique_videos$tags))

#cleaning tag column
tags_docs <- tm_map(tags_docs, toSpace, "/")
tags_docs <- tm_map(tags_docs, toSpace, "@")
tags_docs <- tm_map(tags_docs, toSpace, "\\|")

# Convert the text to lower case
tags_docs <- tm_map(tags_docs, content_transformer(tolower))
# Remove numbers
tags_docs <- tm_map(tags_docs, removeNumbers)
# Remove english common stopwords
tags_docs <- tm_map(tags_docs, removeWords, stopwords("english"))

# Remove punctuations
tags_docs <- tm_map(tags_docs, removePunctuation)
# Eliminate extra white spaces
tags_docs <- tm_map(tags_docs, stripWhitespace)

#convert to matrix
tags_docs<- TermDocumentMatrix(tags_docs)
tag.matrix<- as.matrix(tags_docs)
tag_title_sort<-sort(rowSums(tag.matrix), decreasing=TRUE)

#as.matrix() also gives me an error

```

```{r}

```

